{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "collapsed_sections": [
        "L5eAxki2yNER",
        "93GTMHp_xH9B"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Packages"
      ],
      "metadata": {
        "id": "1kCRujfZx6OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/OSUPCVLab/SegFormer3D.git\n",
        "%cd SegFormer3D\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "!pip install monai accelerate termcolor"
      ],
      "metadata": {
        "id": "W9dVFpz5D5FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from monai.transforms import Transform, MapTransform"
      ],
      "metadata": {
        "id": "DEvoQDXerUgi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMyWGRgLrjD1",
        "outputId": "b129ff60-ad18-4962-a0bc-9d932da06376"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adjust SegFormer3D package to handle BraTs 2023 data"
      ],
      "metadata": {
        "id": "QrY6lWp9Egvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/SegFormer3D/data/brats2023_seg/BraTS2023_Processed_Data\n",
        "!mkdir -p /content/SegFormer3D/data/brats2023_seg/brats2023_raw_data\n",
        "!mkdir -p /content/SegFormer3D/experiments/brats_2023/my_experiment"
      ],
      "metadata": {
        "id": "QONCWsjzOe3y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/SegFormer3D/data/brats2023_seg/brats2023_raw_data/brats2023_seg_preprocess.py\n",
        "import os\n",
        "import torch\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from monai.transforms import Orientation, EnsureType, Transform, MapTransform\n",
        "from monai.utils.enums import TransformBackends\n",
        "from monai.config.type_definitions import NdarrayOrTensor\n",
        "from multiprocessing import Pool\n",
        "\n",
        "\n",
        "class ConvertToMultiChannelBasedOnBrats2023Classes(Transform):\n",
        "    \"\"\"\n",
        "    Convert labels to multi channels based on BraTS 2023 classes:\n",
        "    label 1 is the Nonenhancing Tumor Core (NETC)\n",
        "    label 2 is the Surrounding Non-Enhancing FLAIR Hyperintensity (SNFH)\n",
        "    label 3 is the Enhancing Tumor (ET)\n",
        "    \"\"\"\n",
        "\n",
        "    backend = [TransformBackends.TORCH, TransformBackends.NUMPY]\n",
        "\n",
        "    def __call__(self, img):\n",
        "        # if img has channel dim, squeeze it\n",
        "        if img.ndim == 4 and img.shape[0] == 1:\n",
        "            img = img.squeeze(0)\n",
        "\n",
        "        result = [\n",
        "            (img == 1),  # NETC\n",
        "            (img == 2),  # SNFH\n",
        "            (img == 3)   # ET\n",
        "        ]\n",
        "        return torch.stack(result, dim=0) if isinstance(img, torch.Tensor) else np.stack(result, axis=0)\n",
        "\n",
        "\n",
        "class Brats2023Preprocess:\n",
        "    def __init__(self, root_dir, save_dir=\"/content/drive/MyDrive/BraTs/BraTS2023_Processed_Data\"):\n",
        "        self.root_dir = root_dir\n",
        "        self.save_dir = save_dir\n",
        "        self.MRI_TYPE = [\"t1n\", \"t1c\", \"t2f\", \"t2w\", \"seg\"]\n",
        "        self.case_names = next(os.walk(self.root_dir), (None, None, []))[1]\n",
        "        assert len(self.case_names) > 0, \"No cases found in the directory!\"\n",
        "\n",
        "    def normalize(self, x):\n",
        "        scaler = MinMaxScaler()\n",
        "        normalized = scaler.fit_transform(x.reshape(-1, x.shape[-1])).reshape(x.shape)\n",
        "        return normalized\n",
        "\n",
        "    def load_nifti(self, filepath):\n",
        "        nifti_data = nib.load(filepath)\n",
        "        data = nifti_data.get_fdata()\n",
        "        affine = nifti_data.affine\n",
        "        return data, affine\n",
        "\n",
        "    def preprocess_modality(self, filepath, is_label=False):\n",
        "        data, affine = self.load_nifti(filepath)\n",
        "        if is_label:\n",
        "            data = data.astype(np.uint8)\n",
        "            data = ConvertToMultiChannelBasedOnBrats2023Classes()(data)  # Use custom transform class\n",
        "        else:\n",
        "            data = self.normalize(data)\n",
        "            data = data[np.newaxis, ...]\n",
        "\n",
        "        data = Orientation(axcodes=\"RAS\")(EnsureType()(data))\n",
        "        return data\n",
        "\n",
        "    def process_case(self, case_name):\n",
        "        case_dir = os.path.join(self.root_dir, case_name)\n",
        "        save_case_dir = os.path.join(self.save_dir, case_name)\n",
        "        os.makedirs(save_case_dir, exist_ok=True)\n",
        "\n",
        "        modalities = []\n",
        "        for mri_type in self.MRI_TYPE[:-1]:\n",
        "            filepath = os.path.join(case_dir, f\"{case_name}-{mri_type}.nii\")\n",
        "            modality_data = self.preprocess_modality(filepath, is_label=False)\n",
        "            modalities.append(modality_data)\n",
        "\n",
        "        label_filepath = os.path.join(case_dir, f\"{case_name}-seg.nii\")\n",
        "        label_data = self.preprocess_modality(label_filepath, is_label=True)\n",
        "\n",
        "        modalities = np.concatenate(modalities, axis=0)\n",
        "        torch.save(modalities, os.path.join(save_case_dir, f\"{case_name}_modalities.pt\"))\n",
        "        torch.save(label_data, os.path.join(save_case_dir, f\"{case_name}_label.pt\"))\n",
        "\n",
        "    def preprocess(self):\n",
        "        with Pool() as pool:\n",
        "            pool.map(self.process_case, self.case_names)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    preprocessor = Brats2023Preprocess(root_dir=\"/content/drive/MyDrive/BraTs/brats2023-training\")\n",
        "    preprocessor.preprocess()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYnwAbSWEOJl",
        "outputId": "69a383f0-1929-489f-f5d4-136d310110a5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/SegFormer3D/data/brats2023_seg/brats2023_raw_data/brats2023_seg_preprocess.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/SegFormer3D/dataloaders/brats2023_seg.py\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class Brats2023Dataset(Dataset):\n",
        "    def __init__(self, root_dir, is_train=True, transform=None, fold_id=None):\n",
        "        super().__init__()\n",
        "        csv_name = \"train.csv\" if is_train else \"validation.csv\"\n",
        "        csv_fp = os.path.join(root_dir, csv_name)\n",
        "        assert os.path.exists(csv_fp), f\"CSV file not found: {csv_fp}\"\n",
        "\n",
        "        self.csv = pd.read_csv(csv_fp)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.csv)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data_path = self.csv[\"data_path\"][idx]\n",
        "        case_name = self.csv[\"case_name\"][idx]\n",
        "\n",
        "        volume_fp = os.path.join(data_path, f\"{case_name}_modalities.pt\")\n",
        "        label_fp = os.path.join(data_path, f\"{case_name}_label.pt\")\n",
        "\n",
        "        volume = torch.tensor(torch.load(volume_fp)).float()\n",
        "        label = torch.tensor(torch.load(label_fp)).float()\n",
        "\n",
        "        data = {\"image\": volume, \"label\": label}\n",
        "\n",
        "        if self.transform:\n",
        "            data = self.transform(data)\n",
        "\n",
        "        return data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xnM8BTuEam9",
        "outputId": "438f7f71-5bd4-4d82-b935-cc2546d7eff6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/SegFormer3D/dataloaders/brats2023_seg.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/SegFormer3D/dataloaders/build_dataset.py\n",
        "import sys\n",
        "from typing import Dict\n",
        "from monai.data import DataLoader\n",
        "from augmentations.augmentations import build_augmentations\n",
        "\n",
        "def build_dataset(dataset_type: str, dataset_args: Dict):\n",
        "    if dataset_type == \"brats2023_seg\":\n",
        "        from .brats2023_seg import Brats2023Dataset\n",
        "        dataset = Brats2023Dataset(\n",
        "            root_dir=dataset_args[\"root\"],\n",
        "            is_train=dataset_args[\"train\"],\n",
        "            transform=build_augmentations(dataset_args[\"train\"]),\n",
        "            fold_id=dataset_args[\"fold_id\"],\n",
        "        )\n",
        "        return dataset\n",
        "    else:\n",
        "        raise ValueError(\"only brats2023 segmentation is currently supported!\")\n",
        "\n",
        "def build_dataloader(dataset, dataloader_args: Dict, config: Dict = None, train: bool = True) -> DataLoader:\n",
        "    dataloader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=dataloader_args[\"batch_size\"],\n",
        "        shuffle=dataloader_args[\"shuffle\"],\n",
        "        num_workers=dataloader_args[\"num_workers\"],\n",
        "        drop_last=dataloader_args[\"drop_last\"],\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    return dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnLceUpMEerV",
        "outputId": "e6519a62-89a9-4168-e0f2-cdce21f6a366"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/SegFormer3D/dataloaders/build_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/SegFormer3D/experiments/brats_2023/my_experiment/config.yaml\n",
        "# wandb parameters\n",
        "project: segfmr3d\n",
        "wandb_parameters:\n",
        "  mode: \"offline\" # set this to \"online\" if you want to log to wandb\n",
        "  entity: pcvlab\n",
        "  group: brats2023\n",
        "  name: segformer3d_adamw_batch2_diceloss\n",
        "  resume: False\n",
        "  tags: [\"pcvlab\", \"dice\", \"b0_model\", \"adamw\"]\n",
        "\n",
        "# model parameters\n",
        "model_name: segformer3d\n",
        "model_parameters:\n",
        "  in_channels: 4\n",
        "  sr_ratios: [4, 2, 1, 1]\n",
        "  embed_dims: [32, 64, 160, 256]\n",
        "  patch_kernel_size: [7, 3, 3, 3]\n",
        "  patch_stride: [4, 2, 2, 2]\n",
        "  patch_padding: [3, 1, 1, 1]\n",
        "  mlp_ratios: [4, 4, 4, 4]\n",
        "  num_heads: [1, 2, 5, 8]\n",
        "  depths: [2, 2, 2, 2]\n",
        "  num_classes: 3\n",
        "  decoder_dropout: 0.0\n",
        "  decoder_head_embedding_dim: 256\n",
        "\n",
        "# loss function\n",
        "loss_fn:\n",
        "  loss_type: \"dice\"\n",
        "  loss_args: None\n",
        "\n",
        "# optimizer\n",
        "optimizer:\n",
        "  optimizer_type: \"adamw\"\n",
        "  optimizer_args:\n",
        "    lr: 0.0001\n",
        "    weight_decay: 0.01\n",
        "\n",
        "# schedulers\n",
        "warmup_scheduler:\n",
        "  enabled: True # should be always true\n",
        "  warmup_epochs: 20\n",
        "\n",
        "train_scheduler:\n",
        "  scheduler_type: 'cosine_annealing_wr'\n",
        "  scheduler_args:\n",
        "    t_0_epochs: 400\n",
        "    t_mult: 1\n",
        "    min_lr: 0.000006\n",
        "\n",
        "# (Not fully implemented yet) exponential moving average\n",
        "ema:\n",
        "  enabled: False\n",
        "  ema_decay: 0.999\n",
        "  val_ema_every: 1\n",
        "\n",
        "sliding_window_inference:\n",
        "  sw_batch_size: 4\n",
        "  roi: [128, 128, 128]\n",
        "\n",
        "# gradient clipping (not implemented yet)\n",
        "clip_gradients:\n",
        "  enabled: False\n",
        "  clip_gradients_value: 0.1\n",
        "\n",
        "# training hyperparameters\n",
        "training_parameters:\n",
        "  seed: 42\n",
        "  num_epochs: 800\n",
        "  cutoff_epoch: 400\n",
        "  load_optimizer: False\n",
        "  print_every: 200\n",
        "  calculate_metrics: True\n",
        "  grad_accumulate_steps: 4 # default: 1\n",
        "  checkpoint_save_dir: \"model_checkpoints/best_dice_checkpoint\"\n",
        "  load_checkpoint: # not implemented yet\n",
        "    load_full_checkpoint: False\n",
        "    load_model_only: False\n",
        "    load_checkpoint_path: None\n",
        "\n",
        "# dataset args\n",
        "dataset_parameters:\n",
        "  dataset_type: \"brats2023_seg\"\n",
        "  train_dataset_args:\n",
        "    root: \"../../../data/brats2023_seg\"\n",
        "    train: True\n",
        "    fold_id: null\n",
        "\n",
        "  val_dataset_args:\n",
        "    root: \"../../../data/brats2023_seg\"\n",
        "    train: False\n",
        "    fold_id: null\n",
        "\n",
        "  train_dataloader_args:\n",
        "    batch_size: 4\n",
        "    shuffle: True\n",
        "    num_workers: 8\n",
        "    drop_last: True\n",
        "\n",
        "  val_dataloader_args:\n",
        "    batch_size: 2\n",
        "    shuffle: False\n",
        "    num_workers: 6\n",
        "    drop_last: False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhL7-MHaIhzw",
        "outputId": "8c84dd42-0b2d-40ba-fc9c-999a69e34ab4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/SegFormer3D/experiments/brats_2023/my_experiment/config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "diUjZgZAKp5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-process data"
      ],
      "metadata": {
        "id": "d2q1jmwD_iJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SegFormer3D/data/brats2023_seg/brats2023_raw_data/brats2023_seg_preprocess.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44Tkes7bKprK",
        "outputId": "214eede6-dcfe-410c-a670-9145e235e144"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-09 14:45:06.454717: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-09 14:45:06.454774: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-09 14:45:06.456961: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-09 14:45:07.504585: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize data"
      ],
      "metadata": {
        "id": "ZAhbsn_f_SRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load a sample case and check the labels\n",
        "def check_preprocessed_labels(case_dir, case_name):\n",
        "    label_fp = os.path.join(case_dir, f\"{case_name}/{case_name}_label.pt\")\n",
        "    label = torch.load(label_fp)\n",
        "\n",
        "    print(\"Shape of label tensor:\", label.shape)\n",
        "    unique_classes = torch.unique(label)\n",
        "    print(\"Unique classes in label tensor:\", unique_classes)\n",
        "\n",
        "    return label\n",
        "\n",
        "# Visualize the labels for a specific slice\n",
        "def visualize_labels(label_tensor, slice_idx=70):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
        "    for i in range(3):\n",
        "        axes[i].imshow(label_tensor[i, :, :, slice_idx].numpy(), cmap='gray')\n",
        "        axes[i].set_title(f'Class {i}')\n",
        "        axes[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Path to the preprocessed data directory and sample case name\n",
        "processed_data_dir = '/content/drive/MyDrive/BraTs/BraTS2023_Processed_Data'\n",
        "sample_case_name = 'BraTS-MET-00024-000'\n",
        "\n",
        "# Check and visualize the labels\n",
        "label_tensor = check_preprocessed_labels(processed_data_dir, sample_case_name)\n",
        "visualize_labels(label_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "9Kd15BJA5H2D",
        "outputId": "f43c2d6a-296b-498d-feb5-80bed725728b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of label tensor: torch.Size([3, 240, 240, 155])\n",
            "Unique classes in label tensor: metatensor([False,  True])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-test-split"
      ],
      "metadata": {
        "id": "7aFqHgmu_cGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the processed data directory\n",
        "processed_data_dir = '/content/drive/MyDrive/BraTs/BraTS2023_Processed_Data'\n",
        "\n",
        "# Assume each folder in the processed data directory represents a case\n",
        "cases = [d for d in os.listdir(processed_data_dir) if os.path.isdir(os.path.join(processed_data_dir, d))]\n",
        "\n",
        "# Split cases into train and validation (e.g., 80-20 split)\n",
        "train_cases = cases[:int(len(cases) * 0.8)]\n",
        "val_cases = cases[int(len(cases) * 0.8):]\n",
        "\n",
        "# Create DataFrames\n",
        "train_df = pd.DataFrame({'data_path': [os.path.join(processed_data_dir, c) for c in train_cases], 'case_name': train_cases})\n",
        "val_df = pd.DataFrame({'data_path': [os.path.join(processed_data_dir, c) for c in val_cases], 'case_name': val_cases})\n",
        "\n",
        "# Save to CSV\n",
        "train_df.to_csv('/content/SegFormer3D/data/brats2023_seg/train.csv', index=False)\n",
        "val_df.to_csv('/content/SegFormer3D/data/brats2023_seg/validation.csv', index=False)"
      ],
      "metadata": {
        "id": "fxe_uNWOVMJd"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "ZKSKtDPEEsbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install safetensors>=0.4.1\n",
        "!pip install transformers -U"
      ],
      "metadata": {
        "id": "mNsY_o4PWCFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/SegFormer3D/experiments/brats_2023/my_experiment/\n",
        "!accelerate launch --config_file ./gpu_accelerate.yaml run_experiment.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oLHPjV9I61h",
        "outputId": "3ae33bc4-c119-4299-c5b0-53b55990754c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SegFormer3D/experiments/brats_2023/my_experiment\n",
            "2024-07-09 15:26:47.323597: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-09 15:26:47.323648: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-09 15:26:47.328292: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-09 15:26:48.426965: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "-------------------------------------------------------\n",
            "[info]: Experiment Info\n",
            "[info] ----- Project: \u001b[31msegfmr3d\u001b[0m\n",
            "[info] ----- Group: \u001b[31mbrats2023\u001b[0m\n",
            "[info] ----- Name: \u001b[31msegformer3d_adamw_batch2_diceloss\u001b[0m\n",
            "[info] ----- Batch Size: \u001b[31m4\u001b[0m\n",
            "[info] ----- Num Epochs: \u001b[31m800\u001b[0m\n",
            "[info] ----- Loss: \u001b[31mdice\u001b[0m\n",
            "[info] ----- Optimizer: \u001b[31madamw\u001b[0m\n",
            "[info] ----- Train Dataset Size: \u001b[31m132\u001b[0m\n",
            "[info] ----- Test Dataset Size: \u001b[31m33\u001b[0m\n",
            "[info] ----- Distributed Training: \u001b[31mFalse\u001b[0m\n",
            "[info] ----- Num Classes: \u001b[31m3\u001b[0m\n",
            "[info] ----- EMA: \u001b[31mFalse\u001b[0m\n",
            "[info] ----- Load From Checkpoint: \u001b[31mFalse\u001b[0m\n",
            "[info] ----- Params: \u001b[31m4525251\u001b[0m\n",
            "-------------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "  0% 0/800 [00:00<?, ?it/s]\u001b[31m\n",
            "[info] -- warming up learning rate \n",
            "\u001b[0m\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../dataloaders/brats2023_seg.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  label = torch.tensor(torch.load(label_fp)).float()\n",
            "/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../dataloaders/brats2023_seg.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  label = torch.tensor(torch.load(label_fp)).float()\n",
            "/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../dataloaders/brats2023_seg.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  label = torch.tensor(torch.load(label_fp)).float()\n",
            "/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../dataloaders/brats2023_seg.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  label = torch.tensor(torch.load(label_fp)).float()\n",
            "/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../dataloaders/brats2023_seg.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  label = torch.tensor(torch.load(label_fp)).float()\n",
            "/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../dataloaders/brats2023_seg.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  label = torch.tensor(torch.load(label_fp)).float()\n",
            "/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../dataloaders/brats2023_seg.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  label = torch.tensor(torch.load(label_fp)).float()\n",
            "/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../dataloaders/brats2023_seg.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  label = torch.tensor(torch.load(label_fp)).float()\n",
            "Original x shape: torch.Size([16, 13824, 32])\n",
            "  0% 0/800 [02:56<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/run_experiment.py\", line 240, in <module>\n",
            "    launch_experiment(args.config)\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/run_experiment.py\", line 140, in launch_experiment\n",
            "    trainer.train()\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../train_scripts/trainer_ddp.py\", line 442, in train\n",
            "    self._run_train_val()\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../train_scripts/trainer_ddp.py\", line 261, in _run_train_val\n",
            "    train_loss = self._train_step()\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../train_scripts/trainer_ddp.py\", line 138, in _train_step\n",
            "    predicted = self.model.forward(data)\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../architectures/segformer3d.py\", line 112, in forward\n",
            "    x = self.segformer_encoder(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1582, in _call_impl\n",
            "    result = forward_call(*args, **kwargs)\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../architectures/segformer3d.py\", line 421, in forward\n",
            "    x = blk(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../architectures/segformer3d.py\", line 287, in forward\n",
            "    x = x + self.attention(self.norm1(x))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../architectures/segformer3d.py\", line 216, in forward\n",
            "    x_ = x.permute(0, 2, 1).reshape(B, C, n, n, n)\n",
            "RuntimeError: shape '[16, 13824, 3, 3, 3]' is invalid for input of size 7077888\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/run_experiment.py\", line 240, in <module>\n",
            "    launch_experiment(args.config)\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/run_experiment.py\", line 140, in launch_experiment\n",
            "    trainer.train()\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../train_scripts/trainer_ddp.py\", line 442, in train\n",
            "    self._run_train_val()\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../train_scripts/trainer_ddp.py\", line 261, in _run_train_val\n",
            "    train_loss = self._train_step()\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../train_scripts/trainer_ddp.py\", line 138, in _train_step\n",
            "    predicted = self.model.forward(data)\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../architectures/segformer3d.py\", line 112, in forward\n",
            "    x = self.segformer_encoder(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1582, in _call_impl\n",
            "    result = forward_call(*args, **kwargs)\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../architectures/segformer3d.py\", line 421, in forward\n",
            "    x = blk(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../architectures/segformer3d.py\", line 287, in forward\n",
            "    x = x + self.attention(self.norm1(x))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/SegFormer3D/experiments/brats_2023/my_experiment/../../../architectures/segformer3d.py\", line 216, in forward\n",
            "    x_ = x.permute(0, 2, 1).reshape(B, C, n, n, n)\n",
            "RuntimeError: shape '[16, 13824, 3, 3, 3]' is invalid for input of size 7077888\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/SegFormer3D/experiments/brats_2023/my_experiment/wandb/offline-run-20240709_152651-9p8bbme8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20240709_152651-9p8bbme8/logs\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 986, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 628, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'run_experiment.py']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "4JPXqDlOE5Z_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing results"
      ],
      "metadata": {
        "id": "6EGvZOsdE6_r"
      }
    }
  ]
}